{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This is Oliver's second attempt at sort of baseline model to predict colexification in CLICS.\n",
        "# Here, I was trying to predict p(a and b colexify) in a \"randomly selected\" language. \n",
        "# More specifically, I tried doing this by trying to predict the \"colex.freq\" column divided by the total number of languages in the CLICS.csv file. \n",
        "# This is because if a and b colexify 300 times out of 5000 languages, 300/5000 is a good estimate for the probability they colexify in a \"random\" language\n",
        "# For the input, I converted the senses of each row to their word2vec embeddings. \n",
        "# I used neural networks, XGBoost, and random forest as models"
      ],
      "metadata": {
        "id": "dqNofTszQlLQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ouC6VIGW7kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c090d54-da5c-4e42-c9d5-df73625dc5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 46.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.1\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "! pip install torch-lr-finder\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastai.tabular.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N3TV17S_3xFE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from fastbook import *\n",
        "import gensim.downloader as gs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random as r\n",
        "from torch_lr_finder import LRFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dMSuRajXiRYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040ecdb7-bc29-4425-d7e9-a3405f826db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "wv = gs.load('word2vec-google-news-300') # These are the word2vec embeddings we are using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SGpn2odEXb1g",
        "outputId": "a8472118-8ad0-4d14-c5a7-ad1d9a100328"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   colex.freq Concepticon_Gloss.xo Concepticon_Gloss.yo  vision  assoc  affec  \\\n",
              "0         340                 TREE                 WOOD       1      1      1   \n",
              "1         326                  LEG                 FOOT       1      1      1   \n",
              "2         296                 MOON                MONTH       0      1      1   \n",
              "3         291                   GO                 WALK       0      1      1   \n",
              "4         284                 HAND                  ARM       1      1      1   \n",
              "\n",
              "   tax  fully_covered  \n",
              "0    1              1  \n",
              "1    1              1  \n",
              "2    1              0  \n",
              "3    1              0  \n",
              "4    1              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4529129-e4ec-434f-a1f9-c41e917ace42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>colex.freq</th>\n",
              "      <th>Concepticon_Gloss.xo</th>\n",
              "      <th>Concepticon_Gloss.yo</th>\n",
              "      <th>vision</th>\n",
              "      <th>assoc</th>\n",
              "      <th>affec</th>\n",
              "      <th>tax</th>\n",
              "      <th>fully_covered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>340</td>\n",
              "      <td>TREE</td>\n",
              "      <td>WOOD</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>326</td>\n",
              "      <td>LEG</td>\n",
              "      <td>FOOT</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>296</td>\n",
              "      <td>MOON</td>\n",
              "      <td>MONTH</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>291</td>\n",
              "      <td>GO</td>\n",
              "      <td>WALK</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>284</td>\n",
              "      <td>HAND</td>\n",
              "      <td>ARM</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4529129-e4ec-434f-a1f9-c41e917ace42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4529129-e4ec-434f-a1f9-c41e917ace42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4529129-e4ec-434f-a1f9-c41e917ace42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "NUM_LANGUAGE = 3156 # This is the number of languages used in the CLICS database\n",
        "df = pd.read_csv(\"gdrive/MyDrive/clics-colexification-data.csv\") # Change path as needed\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q2NS5qHFYFwQ"
      },
      "outputs": [],
      "source": [
        "dumb_british_spellings = {\"armour\":\"armor\", \"grey\":\"gray\", \"mould\":\"mold\", \"neighbour\":\"neighbor\", \"axe\":\"ax\", \"moustache\":\"mustache\", \"plough\":\"plow\", \"mandarine\":\"mandarin\"}\n",
        "obscure_words = {\"shoulderblade\":\"shoulder blade\", \"spearthrower\":\"spear thrower\", \"ridgepole\":\"ridge pole\", \"pimpleface\":\"pimple face\", \"tumpline\":\"backpack\", \"cushma\":\"clothing\", \"curassow\":\"tropical bird\", \"banisterium\":\"plant\", \"paca\":\"rodent\", \"netbag\":\"net bag\", \"muntjacs\":\"barking deer\"}\n",
        "\n",
        "# This converts a sense to its word2vec embeddings. More specifically, for each sense I remove punctuation and then add the vectors of each individual word. \n",
        "# I also replace some obscure words and british spellings not recognized by word2vec to similar phrases that word2vec can recognize\n",
        "def stringToVec(s):  \n",
        "  s = s.lower()\n",
        "  for i in \"(),\\t\\n\":\n",
        "    s = s.replace(i, \"\")\n",
        "  for i in \"-\":\n",
        "    s = s.replace(i, \" \")\n",
        "  for i in dumb_british_spellings:\n",
        "    s = s.replace(i, dumb_british_spellings[i])\n",
        "  for i in obscure_words:\n",
        "    s = s.replace(i, obscure_words[i])\n",
        "  arr = s.split(\" \")\n",
        "  vec_defined = False\n",
        "  for i in arr:\n",
        "    try:      # try except gives an error if we can't convert the \n",
        "      if vec_defined:\n",
        "        vec += np.array(wv[i])\n",
        "      else:\n",
        "        vec = np.array(wv[i])\n",
        "        vec_defined = True\n",
        "    except:\n",
        "      continue\n",
        "  if not vec_defined:\n",
        "    raise Exception(\"Word cannot be converted to vector\")\n",
        "  return vec #This will return the string \"error\" if there is not \n",
        "def toTensor(arr):\n",
        "  return torch.tensor(arr, dtype = torch.float32) #Function to easily convert arrays to tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PYCSsx7J8l6m"
      },
      "outputs": [],
      "source": [
        "embed_length = len(wv[\"test\"]) # Length of embeddings in word2vec\n",
        "vec_dic = {} # This will be a dictionary that easily allows us to access the embedding for all of our senses. Note this is not as simple as just calling wv[s] as some senses are phrases\n",
        "error_senses = set()  # This represents the set of senses for which there was a problem converting them to embeddings. The only such sense should be \"AND\" as \"AND\" doesn't appear in word2vec\n",
        "for i in range(len(df)): # Here we loop through each row of our dataframe, and if we can convert a sense s to an embedding then we set vec_dic[s] = embedding\n",
        "  row = df.iloc[i]\n",
        "  x = row[\"Concepticon_Gloss.xo\"]\n",
        "  y = row[\"Concepticon_Gloss.yo\"]\n",
        "  try:   \n",
        "    if x not in vec_dic:\n",
        "      xvec = stringToVec(x)\n",
        "      vec_dic[x] = xvec\n",
        "  except:\n",
        "    error_senses.add(x)\n",
        "\n",
        "  try:  \n",
        "    if y not in vec_dic:\n",
        "      yvec = stringToVec(y)\n",
        "      vec_dic[y] = yvec\n",
        "  except: \n",
        "    error_senses.add(y)\n",
        "\n",
        "error_senses = list(error_senses)\n",
        "senses = list(vec_dic.keys())\n",
        "\n",
        "sense_indices = {senses[i]:i for i in range(len(senses))} # sense_indices is a dictionary where its keys are senses and its values are the indices for which the senses appear in our list of senses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we set up the dependent variables - probability distributions p(?|s) for each sense s, where p(a|b) is (roughly) proportional to how frequently they are colexified in our data set.  \n",
        "\n",
        "# I added a small epsilon term of 0.00001, so the probabilities p(b|a) for are not actually proportional to the colexification frequency\n",
        "# of a and b, but are proportional to colex.freq + epsilon. The reason for this is if a and b don't appear as colexified in our \n",
        "# data set, there is probably a very small but not actually zero probability they colexify\n",
        "# Thus, this epsilon term \"smooths\" our probability distributions\n",
        "\n",
        "epsilon = 0.00001\n",
        "senseToProbVec = {} # This is a dictionary with keys of senses a and values of lists representing the probability distributions p(?|a). More specifically, if sense_indices[s] = i, then the ith element of senseToProbVec[a] is p(s|a)\n",
        "for s in senses:\n",
        "  senseToProbVec[s] = []\n",
        "  for s2 in senses:\n",
        "    senseToProbVec[s].append(epsilon)\n",
        "for i in range(len(df)): # Here we initialize the vectors senseToProvVec[a] so that their ith element is colex.freq of a and the ith sense + epsilon. \n",
        "  row = df.iloc[i]\n",
        "  x = row[\"Concepticon_Gloss.xo\"]\n",
        "  y = row[\"Concepticon_Gloss.yo\"]\n",
        "  amt = int(row[\"colex.freq\"])\n",
        "  if x in vec_dic and y in vec_dic:\n",
        "    senseToProbVec[x][sense_indices[y]] += amt\n",
        "    senseToProbVec[y][sense_indices[x]] += amt \n",
        "for i in senses:\n",
        "  senseToProbVec[i] = np.array(senseToProbVec[i])\n",
        "  senseToProbVec[i] = toTensor(senseToProbVec[i]/sum(senseToProbVec[i])) # Here we normalize the vectors to have sums 1"
      ],
      "metadata": {
        "id": "AP0kF747QHCC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our neural network. \n",
        "# This model recieves an input of a vector representing a word or phrase s in word2vec.\n",
        "# It outputs a vector predicting the probability distributions p(?|s) \n",
        "# We add a dropout layer to prevent overfitting. We output the logs of the probabilities instead of the probabilities since these are used in our KL Divergence loss function.\n",
        "\n",
        "colex_model_2 = nn.Sequential(\n",
        "    nn.Linear(embed_length, 500),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(500, 500),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(500, len(senses)), \n",
        "    nn.Dropout(p=0.5), \n",
        "    nn.LogSoftmax()\n",
        ")"
      ],
      "metadata": {
        "id": "xyezaw-t81Sd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jIZIzUyt-yBH"
      },
      "outputs": [],
      "source": [
        "# Here we set up batches of training and test data\n",
        "\n",
        "input_output_pairs = list(zip([toTensor(vec_dic[s]) for s in senses],  [senseToProbVec[s] for s in senses]))\n",
        "train, test = train_test_split(input_output_pairs, test_size = 0.2, random_state = 0)\n",
        "\n",
        "X_train = torch.stack([i[0] for i in train])\n",
        "y_train = torch.stack([i[1] for i in train])\n",
        "X_test = torch.stack([i[0] for i in test])\n",
        "y_test = torch.stack([i[1] for i in test])\n",
        "\n",
        "trainDL = DataLoader(TensorDataset(X_train,y_train), batch_size = 128)\n",
        "testDL = DataLoader(TensorDataset(X_test,y_test), batch_size = 128)\n",
        "dls = DataLoaders(trainDL, testDL)\n",
        "\n",
        "\n",
        "# Learner is a class in FastAI that does all our model training steps for us\n",
        "# To compare the difference between the probability distributions p(?|a) given by our csv file and the one our model outputs, we use Kullback Leibler divergence\n",
        "# This measures the \"distance\" between two probability distributions\n",
        "\n",
        "learner = Learner(dls, colex_model_2, loss_func = nn.KLDivLoss(reduction = \"batchmean\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a function in fastai that gives you the best learning rate for a model\n",
        "\n",
        "learner.lr_find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "sJ-L10jr3GZm",
        "outputId": "b2102f02-107b-4c91-8ad0-38f2ce37904d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=0.0010000000474974513)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains model for 100 epochs\n",
        "\n",
        "learner.fit_one_cycle(10, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ai2jZyDM2pjr",
        "outputId": "3f71bf26-8847-4181-cdea-4f985c9ced8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.821033</td>\n",
              "      <td>4.326914</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.831506</td>\n",
              "      <td>4.328981</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.864056</td>\n",
              "      <td>4.333940</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.854004</td>\n",
              "      <td>4.328362</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.847218</td>\n",
              "      <td>4.323696</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.823710</td>\n",
              "      <td>4.315085</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.808073</td>\n",
              "      <td>4.307692</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.797514</td>\n",
              "      <td>4.303915</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.783219</td>\n",
              "      <td>4.302636</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.764419</td>\n",
              "      <td>4.302392</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For a given string a (does not have to be a sense), this returns a sorted array of pairs (p(s|a), s) given by inputting a to our model. \n",
        "# Thus, the first element of the array will be the sense that our model thinks a is most likely to colexify with\n",
        "\n",
        "def getHighestProb(word, model):   \n",
        "  dist = model(toTensor(wv[word.lower()]))\n",
        "  probs_senses = [(math.exp(float(dist[i].data)), senses[i]) for i in range(len(senses))]\n",
        "  probs_senses.sort(reverse = True)\n",
        "  return [i[1] for i in probs_senses]\n",
        "\n",
        "\n",
        "print(\"Highest probability senses to colexify with fantasy: \", getHighestProb(\"fantasy\", colex_model_2)[:5])\n",
        "print(\"Highest probability senses to colexify with maze: \", getHighestProb(\"maze\", colex_model_2)[:5])\n",
        "print(\"Highest probability senses to colexify with orthogonal: \", getHighestProb(\"orthogonal\", colex_model_2)[:5])\n",
        "print(\"Highest probability senses to colexify with judicial: \", getHighestProb(\"judicial\", colex_model_2)[:5])\n",
        "print(\"Highest probability senses to colexify with milky: \", getHighestProb(\"milky\",colex_model_2)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONkxmchr4uHF",
        "outputId": "91584c47-8021-436f-f3b7-665903f73511"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest probability senses to colexify with fantasy:  ['MIND', 'THOUGHT', 'MESSAGE', 'SPIRIT', 'SHADE']\n",
            "Highest probability senses to colexify with maze:  ['STONE', 'STONE OR ROCK', 'MIRROR', 'PINE', 'NEST']\n",
            "Highest probability senses to colexify with orthogonal:  ['LIGHTNING', 'DRUNK', 'TREE (CLASSIFIER)', 'ONE TIME', 'HEIGHT']\n",
            "Highest probability senses to colexify with judicial:  ['JUDGMENT', 'ADJUDICATE', 'CONDEMN', 'GUARD', 'PROMISE']\n",
            "Highest probability senses to colexify with milky:  ['LIGHTNING', 'YELLOW', 'FINGER', 'BRACKISH', 'THICK']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CLICS Model 2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}